
🚕📊 NYC Taxi Trips Data Pipeline – Azure + Databricks + Delta Lake

<img width="792" height="398" alt="Screenshot 2025-08-20 at 2 43 38 PM" src="https://github.com/user-attachments/assets/13e46079-9e20-4d25-a7c6-361ae0c23005" />


Excited to share my recent end-to-end data engineering project where I built a scalable data pipeline using the 2024 NYC Taxi Trips dataset!

<img width="1022" height="427" alt="Screenshot 2025-08-20 at 2 39 04 PM" src="https://github.com/user-attachments/assets/5793baaa-6a59-4064-898b-758a047c10a9" />
🔹 Ingestion: Data ingested from APIs using Azure Data Factory
🔹 Storage: Landed into Azure Data Lake Gen2 (Raw Zone – Parquet format)
🔹 Transformation: Processed & cleaned using Databricks (Apache Spark)
🔹 Serving Layer: Optimized with Delta Lake for reliable, query-ready data![Up
loading Screenshot 2025-08-20 at 2.39.04 PM.png…]()

<img width="883" height="310" alt="Screenshot 2025-08-20 at 2 41 07 PM" src="https://github.com/user-attachments/assets/4dc9b4a1-cefa-43c7-a58c-a74661054779" />

🏅 Key Learnings & Highlights
	•	Designed a multi-zone architecture (Raw → Transformed → Serving)
	•	Implemented Parquet + Delta Lake formats for performance & reliability
	•	Hands-on experience with Azure cloud ecosystem and data engineering best practices
<img width="750" height="564" alt="Screenshot 2025-08-20 at 2 50 59 PM" src="https://github.com/user-attachments/assets/abef7c24-a810-4ba1-9495-37e486efb327" />

This project gave me a deeper understanding of how modern data pipelines are structured in real-world scenarios — from ingestion to serving for analytics & BI use cases.

🌟 Next step: Extending this pipeline with orchestration using Apache Airflow and loading into Snowflake for analytics.

Would love to hear thoughts/feedback from data engineers and cloud practitioners! 🚀

#Azure #Databricks #DeltaLake #DataEngineering #BigData #NYCTaxi #CloudComputing
